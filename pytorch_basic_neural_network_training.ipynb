{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image classification test based on basic neural network\n",
    "\n",
    "pp. 58\n",
    "\n",
    "1. Read the data: Transform the data into tensors, the input shape for the network.\n",
    "2. Define the network (using Multi Layer Perceptron)\n",
    "3. Define loss function\n",
    "4. Define optimization\n",
    "5. Train the network\n",
    "6. Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../CIFAR10/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# 1. READ THE DATA: Download the dataset \"CIFAR-10\"\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../CIFAR10', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../CIFAR10', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "print(image.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.size()) # loaded tensors\n",
    "    print(images[0].size()) # first batch\n",
    "    print(labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DEFINE THE NETWORK: based on MLP\n",
    "\n",
    "num_classes = 10\n",
    "class MLPNet (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 600) # fully connected layer 1\n",
    "        self.fc2 = nn.Linear(600, 600)     # fully connected layer 2\n",
    "        self.fc3 = nn.Linear(600, num_classes) # fully connected layer 3\n",
    "        self.dropout1 = nn.Dropout2d(0.2) # droptout layer 1\n",
    "        self.dropout2 = nn.Dropout2d(0.2) # dropout layer 2\n",
    "        \n",
    "    def foward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        return F.relu(self.fc3(x))\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = MLPNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 & 4. DEFINE LOSS FUNCTION AND OPTIMIZATION\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. TRAIN THE NETWORK\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    \n",
    "    ##### train #####\n",
    "    net.train()\n",
    "    for i (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.view(-1, 32*32*3).to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss +=loss.item()\n",
    "        train_acc += (outputs.max(1)[1]==labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "    \n",
    "    ##### evaluation #####\n",
    "    net.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
